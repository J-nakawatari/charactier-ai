#!/usr/bin/env ts-node

import * as fs from 'fs';
import * as path from 'path';
import * as tar from 'tar';
import * as readline from 'readline';
import { execSync } from 'child_process';

interface ErrorEntry {
  timestamp: string;
  method: string;
  url: string;
  status: number;
  source: 'nginx' | 'backend' | 'frontend';
  details?: string;
}

interface VersionInfo {
  file: string;
  name: string;
  version: string;
}

class LogAnalyzer {
  private errors: ErrorEntry[] = [];
  private versions: VersionInfo[] = [];
  private tempDir: string;

  constructor(private tarFile: string) {
    this.tempDir = path.join(path.dirname(tarFile), 'temp_extracted');
  }

  async analyze() {
    console.log('ğŸ“¦ Extracting log files...');
    await this.extractTar();

    console.log('ğŸ“Š Analyzing logs...');
    await this.analyzeNginxLogs();
    await this.analyzeBackendLogs();
    await this.analyzeFrontendLogs();
    await this.analyzeVersions();

    console.log('ğŸ“ Generating report...');
    await this.generateReport();

    console.log('ğŸ§¹ Cleaning up...');
    this.cleanup();
  }

  private async extractTar() {
    if (fs.existsSync(this.tempDir)) {
      execSync(`rm -rf ${this.tempDir}`);
    }
    fs.mkdirSync(this.tempDir, { recursive: true });

    await tar.x({
      file: this.tarFile,
      cwd: this.tempDir
    });
  }

  private async analyzeNginxLogs() {
    const nginxLogPath = path.join(this.tempDir, 'nginx.log');
    if (!fs.existsSync(nginxLogPath)) return;

    const fileStream = fs.createReadStream(nginxLogPath);
    const rl = readline.createInterface({
      input: fileStream,
      crlfDelay: Infinity
    });

    const errorPattern = /(\d+\/\w+\/\d+:\d+:\d+:\d+) .* "(\w+) ([^"]+)" (\d+)/;

    for await (const line of rl) {
      const match = line.match(errorPattern);
      if (match) {
        const [, timestamp, method, url, status] = match;
        const statusCode = parseInt(status);
        
        if ([400, 404, 502, 504].includes(statusCode)) {
          this.errors.push({
            timestamp,
            method,
            url,
            status: statusCode,
            source: 'nginx'
          });
        }
      }
    }
  }

  private async analyzeBackendLogs() {
    const backendLogPath = path.join(this.tempDir, 'backend.log');
    if (!fs.existsSync(backendLogPath)) return;

    const fileStream = fs.createReadStream(backendLogPath);
    const rl = readline.createInterface({
      input: fileStream,
      crlfDelay: Infinity
    });

    const errorPattern = /(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}).*\[ERROR\].*?(\w+)\s+([^\s]+).*?(\d{3})/;
    const routePattern = /Route not found.*?(\w+)\s+([^\s]+)/;

    for await (const line of rl) {
      // Check for explicit error logs
      if (line.includes('[ERROR]')) {
        const match = line.match(errorPattern);
        if (match) {
          const [, timestamp, method, url, status] = match;
          this.errors.push({
            timestamp,
            method,
            url,
            status: parseInt(status),
            source: 'backend',
            details: line
          });
        }
      }

      // Check for route not found
      const routeMatch = line.match(routePattern);
      if (routeMatch) {
        const [, method, url] = routeMatch;
        const timestamp = line.match(/(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})/)?.[1] || 'unknown';
        this.errors.push({
          timestamp,
          method,
          url,
          status: 404,
          source: 'backend',
          details: 'Route not found'
        });
      }
    }
  }

  private async analyzeFrontendLogs() {
    const frontendLogPath = path.join(this.tempDir, 'frontend.log');
    if (!fs.existsSync(frontendLogPath)) return;

    const fileStream = fs.createReadStream(frontendLogPath);
    const rl = readline.createInterface({
      input: fileStream,
      crlfDelay: Infinity
    });

    const errorPattern = /(\w+)\s+([^\s]+).*?(\d{3})/;

    for await (const line of rl) {
      if (line.includes('error') || line.includes('Error')) {
        const match = line.match(errorPattern);
        if (match) {
          const [, method, url, status] = match;
          const statusCode = parseInt(status);
          if ([400, 404, 502, 504].includes(statusCode)) {
            this.errors.push({
              timestamp: new Date().toISOString(),
              method,
              url,
              status: statusCode,
              source: 'frontend',
              details: line
            });
          }
        }
      }
    }
  }

  private async analyzeVersions() {
    // Check versions.txt
    const versionsPath = path.join(this.tempDir, 'versions.txt');
    if (fs.existsSync(versionsPath)) {
      const content = fs.readFileSync(versionsPath, 'utf-8');
      const lines = content.split('\n');
      
      lines.forEach(line => {
        const match = line.match(/(.+?):\s*v?(.+)/);
        if (match) {
          this.versions.push({
            file: 'versions.txt',
            name: match[1].trim(),
            version: match[2].trim()
          });
        }
      });
    }

    // Check package.json files
    const checkPackageJson = (dir: string, prefix: string) => {
      const pkgPath = path.join(this.tempDir, dir, 'package.json');
      if (fs.existsSync(pkgPath)) {
        const pkg = JSON.parse(fs.readFileSync(pkgPath, 'utf-8'));
        this.versions.push({
          file: `${dir}/package.json`,
          name: `${prefix} (${pkg.name})`,
          version: pkg.version
        });

        // Check key dependencies
        const keyDeps = ['next', 'express', 'axios', 'typescript'];
        Object.entries(pkg.dependencies || {}).forEach(([name, version]) => {
          if (keyDeps.includes(name)) {
            this.versions.push({
              file: `${dir}/package.json`,
              name: `${prefix} ${name}`,
              version: version as string
            });
          }
        });
      }
    };

    checkPackageJson('frontend', 'Frontend');
    checkPackageJson('backend', 'Backend');
  }

  private async generateReport() {
    const reportPath = path.join('docs', 'prod-error-report.md');
    
    let report = `# æœ¬ç•ªç’°å¢ƒã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ

ç”Ÿæˆæ—¥æ™‚: ${new Date().toISOString()}
å¯¾è±¡ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: ${path.basename(this.tarFile)}

## ã‚¨ãƒ©ãƒ¼ã‚µãƒãƒªãƒ¼

`;

    // Group errors by status code
    const errorsByStatus = this.errors.reduce((acc, err) => {
      if (!acc[err.status]) acc[err.status] = [];
      acc[err.status].push(err);
      return acc;
    }, {} as Record<number, ErrorEntry[]>);

    Object.entries(errorsByStatus).sort(([a], [b]) => parseInt(a) - parseInt(b)).forEach(([status, errors]) => {
      report += `### ${status} ã‚¨ãƒ©ãƒ¼ (${errors.length}ä»¶)\n\n`;
      
      // Group by URL
      const byUrl = errors.reduce((acc, err) => {
        if (!acc[err.url]) acc[err.url] = [];
        acc[err.url].push(err);
        return acc;
      }, {} as Record<string, ErrorEntry[]>);

      Object.entries(byUrl).forEach(([url, urlErrors]) => {
        report += `#### ${url}\n`;
        report += `- ç™ºç”Ÿå›æ•°: ${urlErrors.length}å›\n`;
        report += `- ãƒ¡ã‚½ãƒƒãƒ‰: ${[...new Set(urlErrors.map(e => e.method))].join(', ')}\n`;
        report += `- ã‚½ãƒ¼ã‚¹: ${[...new Set(urlErrors.map(e => e.source))].join(', ')}\n`;
        
        // Show sample timestamp
        if (urlErrors[0].timestamp !== 'unknown') {
          report += `- æœ€åˆã®ç™ºç”Ÿ: ${urlErrors[0].timestamp}\n`;
        }
        
        report += '\n';
      });
    });

    // Add version information
    report += `## ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±

### versions.txt
`;
    const versionsTxt = this.versions.filter(v => v.file === 'versions.txt');
    versionsTxt.forEach(v => {
      report += `- ${v.name}: ${v.version}\n`;
    });

    report += `
### package.json ãƒãƒ¼ã‚¸ãƒ§ãƒ³
`;
    const packageVersions = this.versions.filter(v => v.file.includes('package.json'));
    packageVersions.forEach(v => {
      report += `- ${v.name}: ${v.version}\n`;
    });

    // Add analysis
    report += `
## åˆ†æçµæœ

### ä¸»è¦ãªå•é¡Œ

1. **502 Bad Gateway ã‚¨ãƒ©ãƒ¼**
   - åŸå› : ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ãŒèµ·å‹•ã—ã¦ã„ãªã„ã€ã¾ãŸã¯Nginxã‹ã‚‰æ¥ç¶šã§ããªã„
   - å½±éŸ¿: ã™ã¹ã¦ã®ãƒšãƒ¼ã‚¸ã§ã‚¢ã‚¯ã‚»ã‚¹ä¸å¯

2. **404 Not Found ã‚¨ãƒ©ãƒ¼**
   - ä¸»ãªåŸå› : APIãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ä¸ä¸€è‡´ï¼ˆ/api/ vs /api/v1/ï¼‰
   - å½±éŸ¿ã‚’å—ã‘ã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ:
`;

    const notFoundErrors = this.errors.filter(e => e.status === 404);
    const uniqueUrls = [...new Set(notFoundErrors.map(e => e.url))];
    uniqueUrls.forEach(url => {
      report += `     - ${url}\n`;
    });

    report += `
### æ¨å¥¨ã•ã‚Œã‚‹å¯¾å‡¦æ³•

1. **å³æ™‚å¯¾å¿œ**
   - ã‚µãƒ¼ãƒ“ã‚¹ã®å†èµ·å‹•: \`sudo systemctl restart charactier-backend charactier-frontend\`
   - ä¾å­˜é–¢ä¿‚ã®æ›´æ–°: \`npm install\` (ä¸¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§å®Ÿè¡Œ)
   - ãƒ“ãƒ«ãƒ‰ã®å®Ÿè¡Œ: \`npm run build\` (ä¸¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§å®Ÿè¡Œ)

2. **è¨­å®šç¢ºèª**
   - .envãƒ•ã‚¡ã‚¤ãƒ«ã« \`API_VERSION=v1\` ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
   - Nginxè¨­å®šãŒæœ€æ–°ã‹ç¢ºèª

3. **ãƒ‡ãƒ—ãƒ­ã‚¤æ‰‹é †**
   \`\`\`bash
   git pull origin main
   cd backend && npm install && npm run build
   cd ../frontend && npm install && npm run build
   sudo systemctl restart charactier-backend charactier-frontend
   \`\`\`
`;

    fs.writeFileSync(reportPath, report);
    console.log(`âœ… Report generated: ${reportPath}`);
  }

  private cleanup() {
    if (fs.existsSync(this.tempDir)) {
      execSync(`rm -rf ${this.tempDir}`);
    }
  }
}

// Main execution
async function main() {
  const args = process.argv.slice(2);
  if (args.length === 0) {
    console.error('Usage: ts-node analyzeLogs.ts <tar.gz file>');
    process.exit(1);
  }

  const tarFile = args[0];
  if (!fs.existsSync(tarFile)) {
    console.error(`File not found: ${tarFile}`);
    process.exit(1);
  }

  const analyzer = new LogAnalyzer(tarFile);
  await analyzer.analyze();
}

main().catch(console.error);